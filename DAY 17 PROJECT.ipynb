{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eebKiotR4vWr"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUIntPML4w8j",
        "outputId": "4f007ba5-d70f-419b-f60a-84dc70095825"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RsS-nSCi_8",
        "outputId": "56a2e9fc-44df-440d-d2d2-49caa565b555"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Collecting openai\n",
            "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed openai-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load OpenRouter API key\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"RITAM'S_KEY\")\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",  # cheaper + sufficient\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "You are an expert Computer Vision and Machine Learning analyst specializing in unsupervised image clustering.\n",
        "\n",
        "Analyze the given image (or image embedding) and assign it to an unsupervised cluster.\n",
        "Explain the visual reasoning briefly.\n",
        "\n",
        "Respond strictly in JSON:\n",
        "\n",
        "{\n",
        "  \"cluster_id\": \"<integer>\",\n",
        "  \"reasoning\": \"<short explanation>\",\n",
        "  \"confidence\": \"<percentage from 0-100>\"\n",
        "}\n",
        "\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    max_tokens=300\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p85s9MnT4901",
        "outputId": "b8ab56f2-83d5-4472-cf7e-badf20017a44"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"cluster_id\": 3,\n",
            "  \"reasoning\": \"The image contains mostly text with dense formatting and tables, indicating it belongs to a cluster of document images focused on structured information.\",\n",
            "  \"confidence\": \"85\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_description_prompt = \"\"\"\n",
        "You are a computer vision annotation system for unlabeled image clustering.\n",
        "\n",
        "Task:\n",
        "Analyze the image and return concise, objective metadata that helps group visually similar images.\n",
        "\n",
        "Rules:\n",
        "- Description: 1 sentence. State main subject, indoor/outdoor setting, and visible action or pose.\n",
        "- Text content: If no readable text, return null. Otherwise transcribe exactly.\n",
        "- Keywords: Provide 8–10 visual keywords focused on similarity (e.g., person, pet, indoor, outdoor, group, close-up).\n",
        "- If the image is blurry, low-resolution, or ambiguous, mention it.\n",
        "- Output RAW JSON only. No markdown or explanations.\n",
        "\n",
        "Output JSON format:\n",
        "{\n",
        "  \"main_subject\": \"string\",\n",
        "  \"detailed_description\": \"string\",\n",
        "  \"visual_elements\": [\"string\"],\n",
        "  \"text_content\": \"string or null\",\n",
        "  \"search_keywords\": [\"string\"]\n",
        "}\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2w8M6E9l77Xn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import mimetypes\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load OpenRouter API key from Colab Secrets\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"RITAM'S_KEY\")\n",
        "\n",
        "# Initialize OpenRouter client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "def encode_image(image_path):\n",
        "    \"\"\"Encodes a local image to base64 string.\"\"\"\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "def generate_search_metadata(image_path, client, prompt_text):\n",
        "    \"\"\"\n",
        "    Generates image metadata using OpenRouter + OpenAI vision model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Detect mime type\n",
        "        mime_type, _ = mimetypes.guess_type(image_path)\n",
        "        if not mime_type:\n",
        "            mime_type = \"image/jpeg\"\n",
        "\n",
        "        # Encode image\n",
        "        img_base64 = encode_image(image_path)\n",
        "\n",
        "        # Call OpenRouter Vision Model\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"openai/gpt-4o-mini\",  # vision + cheap\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": prompt_text},\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:{mime_type};base64,{img_base64}\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            max_tokens=300\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found -> {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Generation error: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "AgXA_rDO8RRO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/Datasets/photos_no_class/asparagus-g4c4164115_640.jpg\"\n",
        "\n",
        "metadata = generate_search_metadata(\n",
        "    image_path=image_path,\n",
        "    client=client,\n",
        "    prompt_text=image_description_prompt\n",
        ")\n",
        "\n",
        "if metadata:\n",
        "    print(metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq8v3trl8j7o",
        "outputId": "d56ad302-cff2-4ecb-e132-d44b5c9e4c04"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"main_subject\": \"food\",\n",
            "  \"detailed_description\": \"A plate of sliced steak accompanied by asparagus and cherry tomatoes, set indoors.\",\n",
            "  \"visual_elements\": [\"steak\", \"asparagus\", \"cherry tomatoes\", \"plate\", \"indoor setting\", \"cooked food\", \"garnish\", \"sliced\"],\n",
            "  \"text_content\": null,\n",
            "  \"search_keywords\": [\"food\", \"indoor\", \"cooked\", \"steak\", \"vegetables\", \"garnish\", \"meal\", \"plated\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "source_folder = \"/content/drive/MyDrive/Datasets/photos_no_class\"\n",
        "output_folder = \"/content/drive/MyDrive/Datasets/photos_json\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Supported image extensions\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.heic')\n",
        "\n",
        "print(f\"Starting processing for images in: {source_folder}\\n\")\n",
        "\n",
        "# Get only valid image files\n",
        "files = [\n",
        "    f for f in os.listdir(source_folder)\n",
        "    if f.lower().endswith(valid_extensions)\n",
        "]\n",
        "\n",
        "files = files[:20]\n",
        "\n",
        "total_files = len(files)\n",
        "processed_count = 0\n",
        "\n",
        "for filename in files:\n",
        "    image_path = os.path.join(source_folder, filename)\n",
        "\n",
        "    json_filename = f\"{os.path.splitext(filename)[0]}.json\"\n",
        "    json_path = os.path.join(output_folder, json_filename)\n",
        "\n",
        "    if os.path.exists(json_path):\n",
        "        print(f\"[{processed_count + 1}/{total_files}] Skipping: {filename} (JSON already exists)\")\n",
        "        processed_count += 1\n",
        "        continue\n",
        "\n",
        "    print(f\"[{processed_count + 1}/{total_files}] Generating metadata for: {filename}...\")\n",
        "\n",
        "    try:\n",
        "        response_text = generate_search_metadata(\n",
        "            image_path=image_path,\n",
        "            client=client,\n",
        "            prompt_text=image_description_prompt\n",
        "        )\n",
        "\n",
        "        if not response_text:\n",
        "            print(f\"   -> Skipped {filename} (Empty response)\")\n",
        "            processed_count += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            description = json.loads(response_text)\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"   -> Invalid JSON for {filename}\")\n",
        "            print(response_text)\n",
        "            processed_count += 1\n",
        "            continue\n",
        "\n",
        "        data = {\n",
        "            \"file_path\": image_path,\n",
        "            \"description\": description\n",
        "        }\n",
        "\n",
        "        with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "            json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"   -> Saved to {json_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   -> Error processing {filename}: {e}\")\n",
        "\n",
        "    processed_count += 1\n",
        "\n",
        "print(\"\\n--- Processing Complete (First 20 Images Only) ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPuW_EbI80WW",
        "outputId": "139b4d3e-9707-4f8a-ff68-a87577b6c73d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing for images in: /content/drive/MyDrive/Datasets/photos_no_class\n",
            "\n",
            "[1/20] Skipping: asparagus-g4c4164115_640.jpg (JSON already exists)\n",
            "[2/20] Skipping: beanie-g4c423e47b_640.jpg (JSON already exists)\n",
            "[3/20] Skipping: bibimbap-gf29abdbf1_640.jpg (JSON already exists)\n",
            "[4/20] Skipping: cat-g0052cc4e9_640.jpg (JSON already exists)\n",
            "[5/20] Skipping: cat-g0fcd844a4_640.jpg (JSON already exists)\n",
            "[6/20] Skipping: cat-g11b1f4535_640.jpg (JSON already exists)\n",
            "[7/20] Skipping: cat-g4ae5d18aa_640.jpg (JSON already exists)\n",
            "[8/20] Skipping: cat-g4fe5d8c20_640.jpg (JSON already exists)\n",
            "[9/20] Skipping: cat-g6052b543b_640.jpg (JSON already exists)\n",
            "[10/20] Skipping: cat-ga3a48da6e_640.jpg (JSON already exists)\n",
            "[11/20] Skipping: cat-gaf654b3a3_640.jpg (JSON already exists)\n",
            "[12/20] Skipping: cat-gf324dae69_640.jpg (JSON already exists)\n",
            "[13/20] Generating metadata for: cave-g68bd31d20_640.jpg...\n",
            "   -> Saved to cave-g68bd31d20_640.json\n",
            "[14/20] Skipping: champon-g31fa88e14_640.jpg (JSON already exists)\n",
            "[15/20] Skipping: chicken-soup-g76231cf36_640.jpg (JSON already exists)\n",
            "[16/20] Skipping: child-g8f11ee379_640.jpg (JSON already exists)\n",
            "[17/20] Skipping: children-g13a48a038_640.jpg (JSON already exists)\n",
            "[18/20] Skipping: couple-g0b2ee91be_640.jpg (JSON already exists)\n",
            "[19/20] Skipping: dog-g0973e56d5_640.jpg (JSON already exists)\n",
            "[20/20] Skipping: dog-g7dcd325a6_640.jpg (JSON already exists)\n",
            "\n",
            "--- Processing Complete (First 20 Images Only) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q openai langchain chromadb langchain-openai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqFi7adP_QHA",
        "outputId": "cb1cf616-33ce-4255-d991-b7862515f401"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}